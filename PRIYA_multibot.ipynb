{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyuuuuu/roleflextai/blob/main/PRIYA_multibot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d12QHlp8QpX",
        "outputId": "ca386b07-3223-4d6c-d947-ce69f06b1790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (10.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, reportlab, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 reportlab-4.2.5 streamlit-1.39.0 watchdog-5.0.3\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain textblob reportlab streamlit && python -m textblob.download_corpora\n",
        "!pip install -qU langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaM1yxr0Z3p5",
        "outputId": "79241a1a-3102-48a3-a558-a4094cef4ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "##checking area perfectly working\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from textblob import TextBlob\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import pandas as pd\n",
        "\n",
        "# Set your Google API key as an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDeCfka3goQtaqdQFQ6IDW2qkdneps-Otw\"\n",
        "\n",
        "# Initialize app session states\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if \"preferences\" not in st.session_state:\n",
        "    st.session_state.preferences = {}\n",
        "if \"user_sessions\" not in st.session_state:\n",
        "    st.session_state.user_sessions = {}\n",
        "\n",
        "# Function to analyze sentiment of a text message\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity  # -1 (negative) to +1 (positive)\n",
        "\n",
        "def sentiment_label(score):\n",
        "    if score > 0.1:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.1:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Function to generate responses from different bots\n",
        "def get_response(user_query, chat_history, bot_type, temperature, max_tokens, language=\"en\"):\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "    )\n",
        "\n",
        "    # Define bot personalities based on user selection\n",
        "    if bot_type == \"Chef\":\n",
        "        system_message = \"\"\"You are a professional Chef AI, providing a range of recipes and cooking advice.\"\"\"\n",
        "    elif bot_type == \"Teacher\":\n",
        "        system_message = \"\"\"You are a knowledgeable Teacher AI with expertise in various subjects.\"\"\"\n",
        "    elif bot_type == \"Nutritionist\":\n",
        "        system_message = \"\"\"You are a professional Nutritionist AI.\"\"\"\n",
        "    elif bot_type == \"Hr\":\n",
        "        system_message = \"\"\"You are an HR consultant AI assisting freshers in job interview preparation.\"\"\"\n",
        "    elif bot_type == \"Custom\" and st.session_state.custom_system_message:\n",
        "        system_message = st.session_state.custom_system_message\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_message),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Add language choice to the user query\n",
        "    user_query = f\"Translate response to {language}. {user_query}\"\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return chain.stream(\n",
        "        {\n",
        "            \"history\": chat_history,\n",
        "            \"input\": user_query,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Set page title and icon\n",
        "st.set_page_config(page_title=\"Multi-Chatbot App\", page_icon=\"🤖\")\n",
        "st.title(\"Multi-Chatbot App\")\n",
        "\n",
        "# Sidebar for user login\n",
        "with st.sidebar:\n",
        "    st.header(\"User Login\")\n",
        "    user_name = st.text_input(\"Enter your name:\")\n",
        "    if st.button(\"Login\"):\n",
        "        if user_name:\n",
        "            if user_name not in st.session_state.user_sessions:\n",
        "                st.session_state.user_sessions[user_name] = []\n",
        "            st.session_state[\"current_user\"] = user_name\n",
        "            st.success(f\"Welcome, {user_name}!\")\n",
        "        else:\n",
        "            st.error(\"Please enter a valid name.\")\n",
        "\n",
        "# Ensure user is logged in\n",
        "if \"current_user\" in st.session_state:\n",
        "    # Sidebar for bot selection and customization\n",
        "    with st.sidebar:\n",
        "        st.header(\"Choose a Chatbot\")\n",
        "        bot_choice = st.selectbox(\"Select a bot:\", [\"Chef\", \"Teacher\", \"Nutritionist\", \"Hr\", \"Custom\"])\n",
        "\n",
        "        temperature = st.slider(\"Creativity Level (Temperature):\", 0.0, 1.0, 0.5)\n",
        "        max_tokens = st.slider(\"Response Length (Max Tokens):\", 50, 1000, 256)\n",
        "\n",
        "        # Multi-language support\n",
        "        language = st.selectbox(\"Select Response Language:\", [\"en\", \"es\", \"fr\", \"de\"])\n",
        "\n",
        "        # Custom bot option for user-defined system messages\n",
        "        custom_bot = st.checkbox(\"Custom Bot\")\n",
        "        if custom_bot:\n",
        "            st.session_state.custom_system_message = st.text_area(\"Enter custom system message for the bot:\")\n",
        "            bot_choice = \"Custom\"\n",
        "\n",
        "        # Chat history options\n",
        "        if st.button(\"Clear Chat History\"):\n",
        "            st.session_state.chat_history = []\n",
        "            st.success(\"Chat history cleared!\")\n",
        "\n",
        "        # Download conversation button\n",
        "        if st.button(\"Download Conversation (PDF)\"):\n",
        "            conversation = \"\\n\".join([f\"Human: {msg.content}\" if isinstance(msg, HumanMessage) else f\"AI: {msg.content}\" for msg in st.session_state.chat_history])\n",
        "            if conversation:\n",
        "                pdf_file = f\"{user_name}_chat_history.pdf\"\n",
        "                c = canvas.Canvas(pdf_file, pagesize=letter)\n",
        "                width, height = letter\n",
        "                c.setFont(\"Helvetica\", 12)\n",
        "                y = height - 40\n",
        "                for line in conversation.split(\"\\n\"):\n",
        "                    c.drawString(40, y, line)\n",
        "                    y -= 20\n",
        "                    if y < 40:\n",
        "                        c.showPage()\n",
        "                        c.setFont(\"Helvetica\", 12)\n",
        "                        y = height - 40\n",
        "                c.save()\n",
        "                with open(pdf_file, \"rb\") as f:\n",
        "                    st.download_button(label=\"Download PDF\", data=f, file_name=pdf_file, mime=\"application/pdf\")\n",
        "            else:\n",
        "                st.warning(\"No conversation history available to create a PDF.\")\n",
        "\n",
        "        # Download conversation as CSV\n",
        "        if st.button(\"Download Conversation (CSV)\"):\n",
        "            conversation_data = [{\"User\": msg.content if isinstance(msg, HumanMessage) else \"\", \"Bot\": msg.content if isinstance(msg, AIMessage) else \"\"} for msg in st.session_state.chat_history]\n",
        "            df = pd.DataFrame(conversation_data)\n",
        "            csv = df.to_csv(index=False).encode('utf-8')\n",
        "            st.download_button(label=\"Download CSV\", data=csv, file_name=f\"{user_name}_chat_history.csv\", mime=\"text/csv\")\n",
        "\n",
        "    # Display conversation history with sentiment analysis\n",
        "    for message in st.session_state.chat_history:\n",
        "        if isinstance(message, HumanMessage):\n",
        "            sentiment = analyze_sentiment(message.content)\n",
        "            with st.chat_message(\"Human\"):\n",
        "                st.markdown(f\"{message.content} (Sentiment: {sentiment_label(sentiment)})\")\n",
        "        else:\n",
        "            with st.chat_message(\"AI\"):\n",
        "                st.markdown(message.content)\n",
        "\n",
        "    # Get user input\n",
        "    user_query = st.chat_input(\"Your message\")\n",
        "    if user_query:\n",
        "        st.session_state.chat_history.append(HumanMessage(user_query))\n",
        "        st.session_state.user_sessions[st.session_state[\"current_user\"]].append(user_query)\n",
        "\n",
        "        # Display the user message\n",
        "        with st.chat_message(\"Human\"):\n",
        "            st.markdown(user_query)\n",
        "\n",
        "        # Prepare to capture AI response\n",
        "        with st.chat_message(\"AI\"):\n",
        "            message_placeholder = st.empty()\n",
        "            full_response = \"\"\n",
        "\n",
        "            for chunk in get_response(user_query, st.session_state.chat_history, bot_choice, temperature, max_tokens, language):\n",
        "                full_response += chunk\n",
        "                message_placeholder.markdown(full_response)\n",
        "\n",
        "            st.session_state.chat_history.append(AIMessage(full_response))\n",
        "\n",
        "    # Chatbot Analytics Dashboard\n",
        "    with st.expander(\"Chatbot Analytics Dashboard\"):\n",
        "        total_chats = len(st.session_state.user_sessions[st.session_state[\"current_user\"]])\n",
        "        avg_sentiment = sum(analyze_sentiment(msg.content) for msg in st.session_state.chat_history if isinstance(msg, HumanMessage)) / max(len(st.session_state.chat_history), 1)\n",
        "        st.write(\"Total Chat Sessions:\", total_chats)\n",
        "        st.write(\"Average Sentiment Score:\", avg_sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#without login\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from textblob import TextBlob\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import pandas as pd\n",
        "\n",
        "# Set your Google API key as an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDeCfka3goQtaqdQFQ6IDW2qkdneps-Otw\"\n",
        "\n",
        "# Initialize app session states\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if \"preferences\" not in st.session_state:\n",
        "    st.session_state.preferences = {}\n",
        "if \"user_sessions\" not in st.session_state:\n",
        "    st.session_state.user_sessions = {}\n",
        "\n",
        "# Function to analyze sentiment of a text message\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity  # -1 (negative) to +1 (positive)\n",
        "\n",
        "def sentiment_label(score):\n",
        "    if score > 0.1:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.1:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Function to generate responses from different bots\n",
        "def get_response(user_query, chat_history, bot_type, temperature, max_tokens, language=\"en\"):\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "    )\n",
        "\n",
        "    # Define bot personalities based on user selection\n",
        "    if bot_type == \"Chef\":\n",
        "        system_message = \"\"\"You are a professional Chef AI, providing a range of recipes and cooking advice.\"\"\"\n",
        "    elif bot_type == \"Teacher\":\n",
        "        system_message = \"\"\"You are a knowledgeable Teacher AI with expertise in various subjects.\"\"\"\n",
        "    elif bot_type == \"Nutritionist\":\n",
        "        system_message = \"\"\"You are a professional Nutritionist AI.\"\"\"\n",
        "    elif bot_type == \"Hr\":\n",
        "        system_message = \"\"\"You are an HR consultant AI assisting freshers in job interview preparation.\"\"\"\n",
        "    elif bot_type == \"Custom\" and st.session_state.custom_system_message:\n",
        "        system_message = st.session_state.custom_system_message\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_message),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Add language choice to the user query\n",
        "    user_query = f\"Translate response to {language}. {user_query}\"\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return chain.stream(\n",
        "        {\n",
        "            \"history\": chat_history,\n",
        "            \"input\": user_query,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Set page title and icon\n",
        "st.set_page_config(page_title=\"Multi-Chatbot App\", page_icon=\"🤖\")\n",
        "st.title(\"Multi-Chatbot App\")\n",
        "\n",
        "# Sidebar for bot selection and customization\n",
        "with st.sidebar:\n",
        "    st.header(\"Choose a Chatbot\")\n",
        "    bot_choice = st.selectbox(\"Select a bot:\", [\"Chef\", \"Teacher\", \"Nutritionist\", \"Hr\", \"Custom\"])\n",
        "\n",
        "    temperature = st.slider(\"Creativity Level (Temperature):\", 0.0, 1.0, 0.5)\n",
        "    max_tokens = st.slider(\"Response Length (Max Tokens):\", 50, 1000, 256)\n",
        "\n",
        "    # Multi-language support\n",
        "    language = st.selectbox(\"Select Response Language:\", [\"en\", \"es\", \"fr\", \"de\"])\n",
        "\n",
        "    # Custom bot option for user-defined system messages\n",
        "    custom_bot = st.checkbox(\"Custom Bot\")\n",
        "    if custom_bot:\n",
        "        st.session_state.custom_system_message = st.text_area(\"Enter custom system message for the bot:\")\n",
        "        bot_choice = \"Custom\"\n",
        "\n",
        "    # Chat history options\n",
        "    if st.button(\"Clear Chat History\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.success(\"Chat history cleared!\")\n",
        "\n",
        "\n",
        "    if st.button(\"Download Conversation (PDF)\"):\n",
        "        conversation = \"\\n\".join([f\"Human: {msg.content}\" if isinstance(msg, HumanMessage) else f\"AI: {msg.content}\" for msg in st.session_state.chat_history])\n",
        "        if conversation:\n",
        "            pdf_file = \"chat_history.pdf\"\n",
        "            c = canvas.Canvas(pdf_file, pagesize=letter)\n",
        "            width, height = letter\n",
        "            c.setFont(\"Helvetica\", 12)\n",
        "            y = height - 40\n",
        "            for line in conversation.split(\"\\n\"):\n",
        "                c.drawString(40, y, line)\n",
        "                y -= 20\n",
        "                if y < 40:\n",
        "                    c.showPage()\n",
        "                    c.setFont(\"Helvetica\", 12)\n",
        "                    y = height - 40\n",
        "            c.save()\n",
        "            with open(pdf_file, \"rb\") as f:\n",
        "                st.download_button(label=\"Download PDF\", data=f, file_name=pdf_file, mime=\"application/pdf\")\n",
        "        else:\n",
        "            st.warning(\"No conversation history available to create a PDF.\")\n",
        "\n",
        "    # Download conversation as CSV\n",
        "    if st.button(\"Download Conversation (CSV)\"):\n",
        "        conversation_data = [{\"User\": msg.content if isinstance(msg, HumanMessage) else \"\", \"Bot\": msg.content if isinstance(msg, AIMessage) else \"\"} for msg in st.session_state.chat_history]\n",
        "        df = pd.DataFrame(conversation_data)\n",
        "        csv = df.to_csv(index=False).encode('utf-8')\n",
        "        st.download_button(label=\"Download CSV\", data=csv, file_name=\"chat_history.csv\", mime=\"text/csv\")\n",
        "\n",
        "\n",
        "for message in st.session_state.chat_history:\n",
        "    if isinstance(message, HumanMessage):\n",
        "        sentiment = analyze_sentiment(message.content)\n",
        "        with st.chat_message(\"Human\"):\n",
        "            st.markdown(f\"{message.content} (Sentiment: {sentiment_label(sentiment)})\")\n",
        "    else:\n",
        "        with st.chat_message(\"AI\"):\n",
        "            st.markdown(message.content)\n",
        "\n",
        "# Get user input\n",
        "user_query = st.chat_input(\"Your message\")\n",
        "if user_query:\n",
        "    st.session_state.chat_history.append(HumanMessage(user_query))\n",
        "\n",
        "    # Display the user message\n",
        "    with st.chat_message(\"Human\"):\n",
        "        st.markdown(user_query)\n",
        "\n",
        "    # Prepare to capture AI response\n",
        "    with st.chat_message(\"AI\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "\n",
        "        for chunk in get_response(user_query, st.session_state.chat_history, bot_choice, temperature, max_tokens, language):\n",
        "            full_response += chunk\n",
        "            message_placeholder.markdown(full_response)\n",
        "\n",
        "        st.session_state.chat_history.append(AIMessage(full_response))\n",
        "\n",
        "# Chatbot Analytics Dashboard\n",
        "with st.expander(\"Chatbot Analytics Dashboard\"):\n",
        "    total_chats = len(st.session_state.chat_history)\n",
        "    avg_sentiment = sum(analyze_sentiment(msg.content) for msg in st.session_state.chat_history if isinstance(msg, HumanMessage)) / max(len(st.session_state.chat_history), 1)\n",
        "    st.write(\"Total Chat Sessions:\", total_chats)\n",
        "    st.write(\"Average Sentiment Score:\", avg_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6RmxCr2sfO-",
        "outputId": "60206113-a89e-4956-d579-704a57af0898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from textblob import TextBlob\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import pandas as pd\n",
        "\n",
        "# Set your Google API key as an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDeCfka3goQtaqdQFQ6IDW2qkdneps-Otw\"\n",
        "\n",
        "# Initialize app session states\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if \"preferences\" not in st.session_state:\n",
        "    st.session_state.preferences = {}\n",
        "if \"user_sessions\" not in st.session_state:\n",
        "    st.session_state.user_sessions = {}\n",
        "\n",
        "# Function to analyze sentiment of a text message\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity  # -1 (negative) to +1 (positive)\n",
        "\n",
        "def sentiment_label(score):\n",
        "    if score > 0.1:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.1:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Function to generate responses from different bots with domain-specific behavior\n",
        "def get_response(user_query, chat_history, bot_type, temperature, max_tokens, language=\"en\"):\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "    )\n",
        "\n",
        "    # Define domain-specific system messages for each bot\n",
        "    if bot_type == \"Chef\":\n",
        "        system_message = \"\"\"You are a professional Chef AI, specializing in cooking recipes and culinary advice.\n",
        "                           You only respond to questions related to cooking. If a question is not about cooking, politely inform the user that you cannot answer it.\"\"\"\n",
        "    elif bot_type == \"Teacher\":\n",
        "        system_message = \"\"\"You are an expert Teacher AI with knowledge across various subjects. You should only respond to questions related to education and teaching. Do not answer any unrelated queries.\"\"\"\n",
        "    elif bot_type == \"Nutritionist\":\n",
        "        system_message = \"\"\"You are a professional Nutritionist AI. You provide advice about healthy eating, nutrition, and related topics. Do not answer questions outside of this domain.\"\"\"\n",
        "    elif bot_type == \"Hr\":\n",
        "        system_message = \"\"\"You are an HR consultant AI, assisting users with job interview preparation, resume advice, and related topics. Do not answer questions unrelated to HR and employment matters.\"\"\"\n",
        "    elif bot_type == \"Custom\" and st.session_state.custom_system_message:\n",
        "        system_message = st.session_state.custom_system_message\n",
        "\n",
        "    # Create the prompt with domain restrictions\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_message),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Add language choice to the user query\n",
        "    user_query = f\"Translate response to {language}. {user_query}\"\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return chain.stream(\n",
        "        {\n",
        "            \"history\": chat_history,\n",
        "            \"input\": user_query,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Set page title and icon\n",
        "st.set_page_config(page_title=\"Multi-Chatbot App\", page_icon=\"🤖\")\n",
        "st.title(\"Multi-Chatbot App\")\n",
        "\n",
        "# Sidebar for bot selection and customization\n",
        "with st.sidebar:\n",
        "    st.header(\"Choose a Chatbot\")\n",
        "    bot_choice = st.selectbox(\"Select a bot:\", [\"Chef\", \"Teacher\", \"Nutritionist\", \"Hr\", \"Custom\"])\n",
        "\n",
        "    temperature = st.slider(\"Creativity Level (Temperature):\", 0.0, 1.0, 0.5)\n",
        "    max_tokens = st.slider(\"Response Length (Max Tokens):\", 50, 1000, 256)\n",
        "\n",
        "    # Multi-language support\n",
        "    language = st.selectbox(\"Select Response Language:\", [\"en\", \"es\", \"fr\", \"de\"])\n",
        "\n",
        "    # Custom bot option for user-defined system messages\n",
        "    custom_bot = st.checkbox(\"Custom Bot\")\n",
        "    if custom_bot:\n",
        "        st.session_state.custom_system_message = st.text_area(\"Enter custom system message for the bot:\")\n",
        "        bot_choice = \"Custom\"\n",
        "\n",
        "    # Chat history options\n",
        "    if st.button(\"Clear Chat History\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.success(\"Chat history cleared!\")\n",
        "\n",
        "    if st.button(\"Download Conversation (PDF)\"):\n",
        "        conversation = \"\\n\".join([f\"Human: {msg.content}\" if isinstance(msg, HumanMessage) else f\"AI: {msg.content}\" for msg in st.session_state.chat_history])\n",
        "        if conversation:\n",
        "            pdf_file = \"chat_history.pdf\"\n",
        "            c = canvas.Canvas(pdf_file, pagesize=letter)\n",
        "            width, height = letter\n",
        "            c.setFont(\"Helvetica\", 12)\n",
        "            y = height - 40\n",
        "            for line in conversation.split(\"\\n\"):\n",
        "                c.drawString(40, y, line)\n",
        "                y -= 20\n",
        "                if y < 40:\n",
        "                    c.showPage()\n",
        "                    c.setFont(\"Helvetica\", 12)\n",
        "                    y = height - 40\n",
        "            c.save()\n",
        "            with open(pdf_file, \"rb\") as f:\n",
        "                st.download_button(label=\"Download PDF\", data=f, file_name=pdf_file, mime=\"application/pdf\")\n",
        "        else:\n",
        "            st.warning(\"No conversation history available to create a PDF.\")\n",
        "\n",
        "    # Download conversation as CSV\n",
        "    if st.button(\"Download Conversation (CSV)\"):\n",
        "        conversation_data = [{\"User\": msg.content if isinstance(msg, HumanMessage) else \"\", \"Bot\": msg.content if isinstance(msg, AIMessage) else \"\"} for msg in st.session_state.chat_history]\n",
        "        df = pd.DataFrame(conversation_data)\n",
        "        csv = df.to_csv(index=False).encode('utf-8')\n",
        "        st.download_button(label=\"Download CSV\", data=csv, file_name=\"chat_history.csv\", mime=\"text/csv\")\n",
        "\n",
        "\n",
        "for message in st.session_state.chat_history:\n",
        "    if isinstance(message, HumanMessage):\n",
        "        sentiment = analyze_sentiment(message.content)\n",
        "        with st.chat_message(\"Human\"):\n",
        "            st.markdown(f\"{message.content} (Sentiment: {sentiment_label(sentiment)})\")\n",
        "    else:\n",
        "        with st.chat_message(\"AI\"):\n",
        "            st.markdown(message.content)\n",
        "\n",
        "# Get user input\n",
        "user_query = st.chat_input(\"Your message\")\n",
        "if user_query:\n",
        "    st.session_state.chat_history.append(HumanMessage(user_query))\n",
        "\n",
        "    # Display the user message\n",
        "    with st.chat_message(\"Human\"):\n",
        "        st.markdown(user_query)\n",
        "\n",
        "    # Prepare to capture AI response\n",
        "    with st.chat_message(\"AI\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "\n",
        "        for chunk in get_response(user_query, st.session_state.chat_history, bot_choice, temperature, max_tokens, language):\n",
        "            full_response += chunk\n",
        "            message_placeholder.markdown(full_response)\n",
        "\n",
        "        st.session_state.chat_history.append(AIMessage(full_response))\n",
        "\n",
        "# Chatbot Analytics Dashboard\n",
        "with st.expander(\"Chatbot Analytics Dashboard\"):\n",
        "    total_chats = len(st.session_state.chat_history)\n",
        "    avg_sentiment = sum(analyze_sentiment(msg.content) for msg in st.session_state.chat_history if isinstance(msg, HumanMessage)) / max(len(st.session_state.chat_history), 1)\n",
        "    st.write(\"Total Chat Sessions:\", total_chats)\n",
        "    st.write(\"Average Sentiment Score:\", avg_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS04L1zl9k52",
        "outputId": "8003fe49-37ca-4547-9362-d790e6f1ce90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHBJ6Bbs8g9M",
        "outputId": "da07f637-e1ba-47ab-e91e-1eeb08c4978b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "up to date, audited 23 packages in 702ms\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEW0XmQU8wmU",
        "outputId": "c3ff9826-0b48-4a38-dff7-3df3764ebcd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.194.240.171\n",
            "your url is: https://big-streets-boil.loca.lt\n",
            "/content/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:14237 (check your firewall settings)\n",
            "    at Socket.<anonymous> \u001b[90m(/content/\u001b[39mnode_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11\u001b[90m)\u001b[39m\n",
            "\u001b[90m    at Socket.emit (node:events:513:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:157:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:122:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (node:internal/process/task_queues:83:21)\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}